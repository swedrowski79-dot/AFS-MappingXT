# github_issues.yml
# Automatische Umbau-Tasks für die bestehende AFS ↔ SQLite ↔ XT-Commerce Schnittstelle
# Projekt: Welafix AFS Mapping-Refactor
# Autor: ChatGPT (GPT-5)
# Version: 1.0

issues:

  - title: "[REF] Bestehende Schnittstelle analysieren & Migrationsplan erstellen"
    body: |
      **Ziel:**  
      Analyse des aktuellen PHP-Codes unter `/classes` und `/api`.  
      Erfasse alle Klassen, die Daten zwischen AFS, SQLite und XT-Commerce austauschen.

      **To-Dos:**
      - [ ] Hauptklassen und Methoden erfassen (`AFS_Get_Data`, `AFS_Evo_*`, `DeltaExporter`, etc.)
      - [ ] Dokument „Before/After“ Architektur erstellen
      - [ ] Kandidaten für Mapping-Integration markieren

      **Akzeptanzkriterien:**
      - Übersicht liegt im Repo (`docs/architecture_before_after.md`)
      - Verantwortlichkeiten pro Klasse beschrieben
    labels: [refactor, analysis]

  - title: "[REF] Projektstruktur für Mapping & Delta vorbereiten"
    body: |
      **Ziel:**  
      Erstelle Verzeichnisse und leere Dateien für das neue Mapping-System.

      **To-Dos:**
      - [ ] `/mappings/` Ordner anlegen  
      - [ ] `/src/Mapping/` Ordner anlegen  
      - [ ] Dummy-Klassen `TransformRegistry.php`, `SourceMapper.php`, `TargetMapper.php`
      - [ ] YAML-Files `source_afs.yml` und `target_sqlite.yml` vorbereiten

      **Akzeptanzkriterien:**
      - Projekt baut ohne Fehler  
      - Alte Logik bleibt unverändert
    labels: [setup, refactor]

  - title: "[REF] AFS_Get_Data auf Mapping umstellen (read-side)"
    body: |
      **Ziel:**  
      `AFS_Get_Data` soll AFS-Daten über `source_afs.yml` einlesen statt fest kodierter Feldzuweisungen.

      **To-Dos:**
      - [ ] YAML-Parsing integrieren  
      - [ ] TransformRegistry (trim, basename, map_enum) nutzen  
      - [ ] Rückgabe kompatibel zum bisherigen Format (`Artikel`, `Warengruppe`, `Dokumente`)

      **Akzeptanzkriterien:**
      - Funktional identisches Ergebnis  
      - Keine Codeänderungen in abhängigen Klassen nötig
    labels: [mapping, refactor]

  - title: "[REF] AFS_Evo_ArticleSync auf Target-Mapping umstellen"
    body: |
      **Ziel:**  
      Die Schreiblogik in SQLite soll `target_sqlite.yml` nutzen.

      **To-Dos:**
      - [ ] YAML-Mapping laden  
      - [ ] Tabellennamen und Spalten dynamisch auslesen  
      - [ ] Logging der Mapping-Version einbauen

      **Akzeptanzkriterien:**
      - Gleiche Daten wie bisher  
      - Schreiboperationen vollständig über Mapping steuerbar
    labels: [mapping, refactor]

  - title: "[DELTA] HashManager implementieren & Update-Flag setzen"
    body: |
      **Ziel:**  
      Implementiere `HashManager`, um Änderungen effizient zu erkennen.

      **To-Dos:**
      - [ ] SHA-256 Hash aus Rohfeldern bilden  
      - [ ] Hash in SQLite speichern (`last_imported_hash`, `last_seen_hash`)  
      - [ ] `update = 1`, wenn sich der Hash geändert hat

      **Akzeptanzkriterien:**
      - Hash stabil und deterministisch  
      - Keine signifikante Performance-Einbuße
    labels: [delta, performance, refactor]

  - title: "[DELTA] Delta-Exporter auf Hash/Update-Flag-Basis umstellen"
    body: |
      **Ziel:**  
      `AFS_Evo_DeltaExporter` soll nur geänderte Datensätze exportieren.

      **To-Dos:**
      - [ ] Nur `update = 1` exportieren  
      - [ ] Nach Export Flag auf 0 setzen  
      - [ ] Statistik im Log ausgeben

      **Akzeptanzkriterien:**
      - Delta-Datei enthält ausschließlich geänderte Artikel  
      - Keine Dubletten
    labels: [delta, refactor]

  - title: "[DELTA] Teil-Hashes & selektive Updates integrieren"
    body: |
      **Ziel:**  
      Erweiterung der Hash-Logik um Teilbereiche (`price`, `media`, `content`).

      **To-Dos:**
      - [ ] Mehrere Hash-Scopes berechnen  
      - [ ] Nur betroffene Tabellen updaten  
      - [ ] Felddefinitionen in YAML (`change_detection`) ergänzen

      **Akzeptanzkriterien:**
      - Preis-, Medien- und Inhaltsänderungen getrennt erkennbar  
      - Dokumentation im Code vorhanden
    labels: [delta, optimization]

  - title: "[LOG] Einheitliches Mapping- und Delta-Logging implementieren"
    body: |
      **Ziel:**  
      Konsistentes Logging für alle Mapping- und Delta-Läufe.

      **To-Dos:**
      - [ ] Logformat (JSON oder Text) festlegen  
      - [ ] Mapping-Version, Datensatzanzahl, Änderungen, Dauer loggen  
      - [ ] Output nach `/logs/YYYY-MM-DD.log`

      **Akzeptanzkriterien:**
      - Einheitliche Logstruktur  
      - Alte Logausgaben ersetzt
    labels: [logging, quality]

  - title: "[TEST] Schnittstelle im gemischten Modus (alt+neu) validieren"
    body: |
      **Ziel:**  
      Sicherstellen, dass neue Mapping-Logik identische Ergebnisse liefert.

      **To-Dos:**
      - [ ] Vergleich alter und neuer Lauf  
      - [ ] Prüfen auf Datenverlust  
      - [ ] Performance vergleichen

      **Akzeptanzkriterien:**
      - Ergebnis 100 % identisch  
      - Log dokumentiert Unterschiede
    labels: [testing, refactor]

  - title: "[CLEANUP] Alte Hardcodings & Direktzugriffe entfernen"
    body: |
      **Ziel:**  
      Entferne nach Migration alle statischen Feldzuweisungen und Legacy-SQLs.

      **To-Dos:**
      - [ ] Legacy-Felder löschen  
      - [ ] Nur noch Mapping-Pfad aktiv  
      - [ ] Code vereinfachen

      **Akzeptanzkriterien:**
      - Kein harter Feldname mehr im Code  
      - Nur Mapping-basierte Datenflüsse
    labels: [cleanup, refactor]
